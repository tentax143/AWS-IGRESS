# -*- coding: utf-8 -*-
"""Yet another copy of aws rec sys.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tPzkCUFezGPVzSDdctz2a2JJTirZqzCf
"""

!git clone https://github.com/tentax143/AWS-IGRESS.git

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import tensorflow as tf
import sklearn
from sklearn.decomposition import PCA
from sklearn.linear_model import LinearRegression
from sklearn.svm import LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import GradientBoostingClassifier
from keras.models import Sequential
from keras.layers import Dense
from sklearn.metrics import classification_report

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import pearsonr

df = pd.read_csv('/content/drive/MyDrive/aws rec sys/AWS-CA-DATA.csv')
grouped_df = df.groupby('categoryName')['price'].agg(['mean', 'std'])

plt.figure(figsize=(12, 6))
bar_colors = plt.cm.viridis(np.linspace(0, 1, len(grouped_df)))
plt.bar(grouped_df.index, grouped_df['mean'], color=bar_colors)
plt.xlabel('Product category', rotation=90, ha='center')
plt.ylabel('Mean price')
plt.title('Mean prices across different product categories')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.gca().set_facecolor('black')
plt.show()

plt.figure(figsize=(12, 6))
bar_colors = plt.cm.plasma(np.linspace(0, 1, len(grouped_df)))
plt.bar(grouped_df.index, grouped_df['std'], color=bar_colors)
plt.xlabel('Product category', rotation=90, ha='center')
plt.ylabel('Standard deviation of prices')
plt.title('Standard deviations of prices across different product categories')
plt.xticks(rotation=45, ha='right')
plt.tight_layout()
plt.gca().set_facecolor('black')
plt.show()'], grouped_df['std'])
print('Correlation coefficient:', c
corr, p = pearsonr(grouped_df['meanorr)
print('P-value:', p)

import pandas as pd
import seaborn as sns
from scipy.stats import pearsonr
import matplotlib.pyplot as plt

df = pd.read_csv('/content/drive/MyDrive/aws rec sys/AWS-CA-DATA.csv')

corr, p = pearsonr(df['stars'], df['reviews'])

sns.set(style="whitegrid")

plt.figure(figsize=(10, 6))
sns.regplot(x='stars', y='reviews', data=df, scatter_kws={'s': 50, 'alpha': 0.7}, line_kws={'color': 'red'})

plt.xlabel('Customer rating')
plt.ylabel('Number of reviews')
plt.title('Correlation between customer ratings and the number of reviews')
plt.text(1.5, 250, f'Correlation coefficient: {corr:.2f}\nP-value: {p:.4f}', fontsize=12, color='blue')
plt.show()

"""# New Section"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Load the dataset from a CSV file
file_path = '/content/drive/MyDrive/aws rec sys/AWS-CA-DATA.csv'
df = pd.read_csv(file_path)

# Sort the DataFrame by the number of units bought last month and select top 5
top_5 = df.sort_values(by='boughtInLastMonth', ascending=False).head(5)

# Create a colored graph
plt.figure(figsize=(10, 6))
sns.barplot(x='boughtInLastMonth', y='title', data=top_5, palette='viridis')
plt.title('Top 5 Selling Products')
plt.xlabel('Units Bought Last Month')
plt.ylabel('Product Title')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt
from scipy.stats import pearsonr

df = pd.read_csv('/content/drive/MyDrive/aws rec sys/AWS-CA-DATA.csv', error_bad_lines=False)

corr, p = pearsonr(df['price'], df['stars'])

print('Correlation coefficient:', corr)
print('P-value:', p)

plt.figure(figsize=(10, 6))
plt.scatter(df['price'], df['stars'], alpha=0.7, c=df['price'], cmap='viridis')
plt.xlabel('Price')
plt.ylabel('Customer ratings')
plt.title('Correlation between price and customer ratings')
plt.grid(True)
plt.colorbar(label='Price', orientation='vertical')
plt.gca().set_facecolor('black')
plt.show()

import pandas as pd
import matplotlib.pyplot as plt


df = pd.read_csv('/content/drive/MyDrive/aws rec sys/AWS-CA-DATA.csv')
grouped_df = df.groupby(pd.cut(df['price'], bins=[0, 20, 40, 60, 80, 100]))['asin'].count()


plt.figure(figsize=(12, 6))
bar_colors = plt.cm.viridis(np.linspace(0, 1, len(grouped_df)))
plt.bar(grouped_df.index.astype('str'), grouped_df, color=bar_colors)
plt.xlabel('Price range', rotation=45, ha='right')
plt.ylabel('Number of products')
plt.title('Number of products in each price range')
plt.gca().set_facecolor('black')
plt.show()


percentage_df = grouped_df / df['asin'].count() * 100


plt.figure(figsize=(12, 6))
bar_colors = plt.cm.plasma(np.linspace(0, 1, len(percentage_df)))
plt.bar(percentage_df.index.astype('str'), percentage_df, color=bar_colors)
plt.xlabel('Price range', rotation=45, ha='right')
plt.ylabel('Percentage of products')
plt.title('Percentage of products in each price range')
plt.gca().set_facecolor('black')
plt.show()



!pip install scikit-surprise

from google.colab import drive
drive.mount('/content/drive')



import csv
csv_file_path = '/content/amz_ca_total_products_data_processed.csv'

with open(csv_file_path, 'r', newline='', encoding='utf-8') as file:
    reader = csv.reader(file)

    rows = []

    try:
        for row in reader:

            rows.append(row)
    except csv.Error as e:
        # Handle parsing errors
        print(f'Error parsing CSV file: {e}')

# Now, you have all rows in the 'rows' list
# You can perform any necessary preprocessing or data cleaning here
# For example, you can remove duplicate rows or handle missing values

# Example: Print the first few rows of data
for row in rows[:5]:
    print(row)

"""Term Frequency(TF) : Term frequency, or TF for short, is a key idea in information retrieval and natural language processing. It displays the regularity with which a certain term or word occurs in a text corpus or document. TF is used to rank terms in a document according to their relative value or significance.
The term-frequency can be calculated by:


![image.png](data:image/png;base64,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)

Inverse-document Frequency(IDF): The measure known as Inverse Document Frequency (IDF) is employed in text analysis and information retrieval to evaluate the significance of phrases within a set of documents. IDF measures how uncommon or unique a term is in the corpus. To compute it, take the reciprocal of the fraction of documents that include the term and logarithmize it. Common terms have lower IDF values, while rare terms have higher values. IDF is an essential part of the TF-IDF (Term Frequency-Inverse Document Frequency) method, which uses it to assess the relative importance of terms in different documents. To improve information representation and retrieval from massive text datasets, IDF is used in tasks including document ranking, categorization, and text mining.
The inverse-document frequency can be calculated with:

![image.png](data:image/png;base64,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)

A numerical statistic called Term Frequency-Inverse Document Frequency (TF-IDF) is employed in information retrieval and natural language processing. The term’s significance within a document is assessed in relation to a group of documents (the corpus). TF emphasizes terms with greater frequencies by measuring a term’s frequency of occurrence in a document. IDF evaluates a term’s rarity within the corpus, emphasizing terms that are distinct. A weighted score is produced for each term in a document by multiplying TF and IDF together to compute TF-IDF.

Therefore, the total formula is:

![image.png](data:image/png;base64,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)
"""

import pandas as pd
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split
from surprise import KNNBasic
from surprise import accuracy

# Load data from file and skip the header row
df = pd.read_csv('/content/drive/MyDrive/aws rec sys/AWS-CA-DATA.csv')
df = df[['asin', 'title', 'imgUrl', 'productURL', 'stars', 'reviews', 'price', 'listPrice', 'categoryName', 'isBestSeller', 'boughtInLastMonth']]


df = df[pd.to_numeric(df['reviews'], errors='coerce').notnull()]
t
df['reviews'] = df['reviews'].astype(float)


reader = Reader(rating_scale=(1, 5))
dataset = Dataset.load_from_df(df[['asin', 'title', 'reviews']], reader)


trainset, testset = train_test_split(dataset, test_size=0.2, random_state=42)

model = KNNBasic(sim_options={'user_based': False})
model.fit(trainset)

predictions = model.test(testset)

accuracy.rmse(predictions)

import pandas as pd
from surprise import Dataset, Reader
from surprise.model_selection import train_test_split
from surprise import KNNBasic
from surprise import accuracy

chunk_size = 10000
reader = Reader(rating_scale=(1, 5))

data_chunks = []

for chunk in pd.read_csv('/content/drive/MyDrive/aws rec sys/AWS-CA-DATA.csv', chunksize=chunk_size):
    chunk = chunk[pd.to_numeric(chunk['reviews'], errors='coerce').notnull()]

    chunk['reviews'] = chunk['reviews'].astype(float)

    data_chunks.append(chunk)

df = pd.concat(data_chunks)

dataset = Dataset.load_from_df(df[['asin', 'title', 'reviews']], reader)

trainset, testset = train_test_split(dataset, test_size=0.2, random_state=42)

model = KNNBasic(sim_options={'user_based': False})
model.fit(trainset)

predictions = model.test(testset)

accuracy.rmse(predictions)

import pandas as pd
import numpy as np
from surprise import Dataset, Reader, KNNBasic
from surprise.model_selection import train_test_split
from surprise.accuracy import rmse

file_path = '/content/drive/MyDrive/aws rec sys/AWS-CA-DATA.csv'
df = pd.read_csv(file_path)

df = df[['categoryName', 'asin', 'stars']]

reader = Reader(rating_scale=(1, 5))

data = Dataset.load_from_df(df, reader)

trainset, testset = train_test_split(data, test_size=0.2, random_state=42)

algo = KNNBasic()

algo.fit(trainset)

predictions = algo.test(testset)

accuracy = rmse(predictions)
print(f"RMSE: {accuracy}")

top_n = 5


asins = df['asin'].unique()
random_asin = np.random.choice(asins)

if random_asin in trainset.all_items():
    inner_id = trainset.to_inner_iid(random_asin)

    similar_inner_ids = algo.get_neighbors(inner_id, k=top_n)

    similar_asins = [trainset.to_raw_iid(inner_id) for inner_id in similar_inner_ids]
    print(f"Similar items to ASIN {random_asin}:")
    for asin in similar_asins:
        print(f"- ASIN: {asin}")
else:
    print(f"The random ASIN {random_asin} does not exist in the training set.")

import pandas as pd
from sklearn.model_selection import cross_val_score
from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.naive_bayes import GaussianNB
import xgboost as xgb
from sklearn.preprocessing import LabelEncoder

# Load your dataset into a pandas DataFrame
df = pd.read_csv("/content/drive/MyDrive/aws rec sys/advanced_cleaned_dataset.csv")  # Replace "your_dataset.csv" with the path to your dataset file

# Assuming your dataset has features (X) and labels (y)
X = df.drop(columns=["stars"])  # Replace "label_column" with the name of your label column
y = df["price"]

# Use label encoding to convert the target variable 'y' into numeric format
label_encoder = LabelEncoder()
y_encoded = label_encoder.fit_transform(y)

# Define classifiers
classifiers = {
    "Random Forest": RandomForestClassifier(),
    "K-Nearest Neighbors": KNeighborsClassifier(),
    "Logistic Regression": LogisticRegression(),
    "Decision Tree": DecisionTreeClassifier(),
    "Support Vector Machine": SVC(),
    "Naive Bayes": GaussianNB(),
    "AdaBoost": AdaBoostClassifier(),
    "Gradient Boosting": GradientBoostingClassifier(),
    "XGBoost": xgb.XGBClassifier()
}

# Evaluate classifiers using cross-validation
for clf_name, clf in classifiers.items():
    scores = cross_val_score(clf, X, y_encoded, cv=2)
    print(f"{clf_name}: {scores.mean()*100:.2f}%")